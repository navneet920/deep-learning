{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78b3722b-6faa-4cb8-b188-e38ba666a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d375d70-b90e-4b13-979e-059ac300e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\Navneet\\Downloads/Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d50ca51-782b-4fcf-b9e6-ab67dfb79265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82333190-2f8f-4eca-a4db-b7821c0f1502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a577e5f5-0f12-4d3e-9c25-3473d22b7973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9185ce3a-3f33-42bb-9cea-a9f8a2475762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d66c594-1dc4-4084-a9cb-147547bdb123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "692f9a91-e328-458e-8333-4d716e436038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "395        324          110                  3  3.5   3.5  9.04         1   \n",
       "396        325          107                  3  3.0   3.5  9.11         1   \n",
       "397        330          116                  4  5.0   4.5  9.45         1   \n",
       "398        312          103                  3  3.5   4.0  8.78         0   \n",
       "399        333          117                  4  5.0   4.0  9.66         1   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "395              0.82  \n",
       "396              0.84  \n",
       "397              0.91  \n",
       "398              0.67  \n",
       "399              0.95  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d8bbb2e-f471-4ce5-a2ee-abc4cd51ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "187e9d68-d178-485f-afda-f91cb045ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e84ee69-9a7f-4f34-914c-c125b16cffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d062eb3-74b4-40ae-a8c7-d8cae215dec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3d0b095-3036-4ad7-9215-209d7749b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3d5bb35-71fd-420e-b18e-b0c306e80223",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=MinMaxScaler()\n",
    "X_train_trans=scale.fit_transform(X_train)\n",
    "X_test_trans=scale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20ca2497-336f-454e-b839-6b5f5a1dd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2de07c4-2530-4cb3-8a34-745ee84e4714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Navneet\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3179a78-c79d-41e2-a873-7ee205866bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e2417d5-8795-4643-b04e-357bc55d9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6493f2af-77c7-454c-8801-2db97be08c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.6003 - val_loss: 0.5947\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5317 - val_loss: 0.5185\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4573 - val_loss: 0.4338\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3679 - val_loss: 0.3369\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2774 - val_loss: 0.2472\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2011 - val_loss: 0.1723\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1382 - val_loss: 0.1164\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0922 - val_loss: 0.0767\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0610 - val_loss: 0.0501\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0401 - val_loss: 0.0339\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0277 - val_loss: 0.0250\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0179 - val_loss: 0.0185\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0161 - val_loss: 0.0176\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - val_loss: 0.0163\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0138 - val_loss: 0.0158\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0041 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_trans,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "634ffe12-2f14-4204-8374-e1d9c3df6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1968651-2d13-4089-a0f6-e4fc0e26b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9c46797-b070-44c8-b911-cc08113078cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436965705846069"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a2676f8-a8bd-420d-8f19-bbb727648592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85c88064-c424-46ea-ba35-786b6bb1a50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2761f6c4a50>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438a647-defb-40d2-b240-0a87186d0618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
